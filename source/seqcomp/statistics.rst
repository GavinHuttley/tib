Refresher on statistical inference
==================================

.. sidebar:: Distribution of plant heights
    :name: plant_heights

    .. jupyter-execute::
        :hide-code:

        import plotly.express as px
        from numpy.random import normal

        x_norm = normal(loc=23, scale=2.0, size=50000)
        fig = px.histogram(x=x_norm, histnorm="probability", height=300, width=400)
        fig.layout.xaxis.title = "Plant Height"
        fig.layout.yaxis.title = "Probability"
        fig.layout.title = "Simulated Plant Heights"
        fig.show()

    Values of "plant height" were generated by using pseudo-random numbers drawn from a Normal distribution function with :math:`\mu=23,\sigma=2`.

Where do we get :math:`p`-values from? What is a distribution? Where do we get distributions from?

.. index:: statistical distribution

Let's start by defining a distribution. In statistics, we use the term distribution to describe the occurrence of a random variable. Say we were measuring plant height for a particular species. Plant height will be a "continuously distributed" random variable -- meaning heights can assume an infinite number of values. If we were to plot those heights along an x-axis, then as we continue to obtain new data points we would wind up with having to place points on top of each other. If we continued to do this sampling and plotting we would see a shape emerge (e.g. :ref:`Distribution of plant heights <plant_heights>`). This shape can be thought of as the distribution of the *plant height random variable*. In this hypothetical example, we have obtained our distribution from the data itself.

In bioinformatics, if we're lucky, the random variable of interest belongs to a known distribution that is described by a mathematical function. That function specifies the probability of observing any specific value. Examples include the Normal (or Gaussian) distribution, Gamma distribution and, of particular use to the task of understanding :math:`p`-values, the uniform distribution.

.. index::
    pair: uniform; statistical distribution

.. index:: hypothesis testing, :math:`H_o`

Hypothesis testing and the :math:`p`-value
------------------------------------------

I'm going to present this principally by focussing on the null hypothesis (denoted :math:`H_o`). This corresponds most closely with the approach for data analysis advocated by Fisher (see :cite:`Perezgonzalez:2015aa`).

In this instance, our null corresponds to some notion of how we think the data may be distributed. Let's imagine we have the complete genome sequences of two different species. We could pose the null hypothesis that the abundance of the different nucleotides in the sequence will be the same. To quantify this, we select a statistical procedure for comparing counts data (e.g. a chi-square test) and decide, *a priori*, on our significance threshold (we will choose 0.05 for now, but more on this later). We compute our test-statistic (a :math:`\chi^2` in this hypothetical case) and "look up" the corresponding :math:`p`-value. Say our hypothetical analysis of nucleotide counts returned a :math:`\chi^2=7.9`. Then, given 3 degrees-of-freedom, our p-value is :math:`\approx 0.048<0.05`.

So what does this :math:`p`-value correspond to? First, it's actually a cumulative probability attained by summing the tail of the :math:`\chi^2_3` distribution for all values :math:`\ge 7.9`. So a :math:`p`-value **is not** a point probability (that would be the probability of observing a value of precisely :math:`7.9`). Another point worth making here is that the :math:`p`-value is that expected under the idealised theoretical (mathematical) distribution [1]_.

.. [1] Below I provide a brute-force demonstration that :math:`p`-values derive from the null distribution. I do this by showing a computational technique for estimating a :math:`p`-value from a generated null distribution. I further demonstrate, for that case, that the estimated :math:`p`-value is extremely close to the one obtained by using the theoretical distribution.

Importantly, a :math:`p`-value corresponds to the cumulative probability of observing data that give an equivalent or larger :math:`\chi^2` by chance (from the theoretical distribution) **when the null is True**. (The latter often phrased as "under the null".) Even the rather extreme value 30.66 is possible under the null but, with a :math:`p`-value of :math:`\approx 1\times10^-6`, we can expect to encounter data delivering such a statistic extremely rarely.

A significance threshold is a decision point that you choose. It is a cutoff for you to decide when to reject the null hypothesis as an acceptable explanation for the data. In the Fisherian approach, which does not formalise the role of an alternate hypothesis, this is a sufficient basis for pursuing additional experimental avenues. The :math:`p`-value cannot, however, be proof that the null is wrong. (Given where the :math:`p`-value comes from, I hope that the logical fallacy of such a conclusion is obvious.)

The notion of an alternate hypothesis (denoted :math:`H_a`) originates from the framework of Neyman-Pearson. There are overlaps in outcome with the approach of Fisher, but significant differences too (again, see :cite:`Perezgonzalez:2015aa` for an accessible summary). You will also encounter the Neyman-Pearson approach in the material here.

The uniform distribution
------------------------

We now turn our attention to a description of the uniform distribution which we will use to introduce a measure related to the :math:`p`-value as a cumulative measure of probability density.

Consider a random variable that can obtain any value in [0, 1] (including the boundaries, see :ref:`uniform distribution histogram <uniform_dist>`). We call such a random variable uniformly distributed if all possible values of that random variable have an equal probability of occurring. The probability of a value of 0.2 is equal that of observing of 0.8, 0.9, or 0.0.

.. sidebar:: Histogram of a uniformly distributed random variable
    :name: uniform_dist
    
    Generating some random values from the uniform distribution.
    
    .. jupyter-execute::

        from numpy.random import rand

        x_uniform = rand(50000)
    
    .. jupyter-execute::
        :hide-code:

        import plotly.express as px

        fig = px.histogram(x=x_uniform, histnorm="probability", height=300, width=400)
        fig.layout.xaxis.title = "A Statistic"
        fig.layout.xaxis.range = (0, 1)
        fig.layout.yaxis.title = "Probability"
        fig.show()

.. index::
    pair: quantile; distribution

Quantiles as distribution descriptors
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Quantiles are rank order statistics. They are locations in a sorted collection of values. One example of a quantile you are likely familiar with is the median, which cuts a distribution such that 1/2 of all values are less than it. Following this example, then, a quantile=0.05 is the point that is greater the 1/20th of all values. We can think of a values quantile, then, as its relative rank with a data set which can be computed as :math:`\frac{r}{n}` where :math:`r` is the rank in :math:`n` values.

Let's play with the quantiles from the uniform distribution that I generated above. We use the ``numpy.quantile`` function for this purpose. Since we're using a uniform distribution, and following from the definition of this distribution, we can expect that 5% of all uniform random values will be :math:`\le 0.05`. Does our data support this?

.. jupyter-execute::
    :linenos:

    from numpy import quantile
    
    quantile(x_uniform, 0.05)

Conversely, we expect that 5% of all uniform random values will be :math:`\ge 0.95`

.. jupyter-execute::
    :linenos:

    1 - quantile(x_uniform, 0.95)

We generated these data using a sample size of 50,000. As we increase that sample size, you will find the estimates of the quantiles from the uniform distribution converge on their expected values. We can generalise this statement further, as you increase the sample size the quantile becomes an increasingly good approximation of its :math:`p`-value.

Quantiles have advantages over the :math:`p`-values in exploratory data analysis. Not least of which they are derived from the actual data, rather than idealised (theoretical) description. Numerous data exploratory techniques are based upon this quantity (for example Quantile-Quantile plots to compare the distributions of two data sets).

.. index:: resampling statistic

Resampling statistics -- brute-force generation of null distributions
---------------------------------------------------------------------

A challenge often encountered in bioinformatics is that a random variable of interest does not follow a known distribution. In these case, a popular statistical approach is to use so called resampling approaches.

If they derive from some type of permutation of observed data (as we will do below) then they are often referred to as "non-parametric" methods. Such techniques have value for estimating the confidence interval for a parameter (e.g. jackknife) or estimating a p-value (e.g. permutation tests).

Computational approaches -- resampling with replacement
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

We now consider a specific problem which we will solve using random sampling with replacement [2]_.

.. [2] To illustrate "with replacement". We randomly draw an observation from the observed data set and add it to our "resampled" set. We then return the observation back to the observed data. This means the probability of observing that specific state never changes. In the alternate approach of resampling without replacement, the probability of drawing a specific state decreases with each subsequent draw of it.

A worked example for estimating a p-value using a resampling statistic
----------------------------------------------------------------------

We have a DNA sequence and we want to evaluate whether nucleotides occur randomly in the sequence. We will tackle that question by using non-overlapping dinucleotides and assessing whether their frequency is consistent with the frequencies of their constituent nucleotides.

Here's the sequence we will use.

.. jupyter-execute::
    :linenos:

    seq = [
        "ATGAAATCCAACCAAGAGCGGAGCAACGAATGCCTGCCTCCCAAGAAGCG",
        "CGAGATCCCCGCCACCAGCCGGTCCTCCGAGGAGAAGGCCCCTACCCTGC",
        "CCAGCGACAACCACCGGGTGGAGGGCACAGCATGGCTCCCGGGCAACCCT",
        "GGTGGCCGGGGCCACGGGGGCGGGAGGCATGGGCCGGCAGGGACCTCGGT",
        "GGAGCTTGGTTTACAACAGGGAATAGGTTTACACAAAGCATTGTCCACAG",
        "GGCTGGACTACTCCCCGCCCAGCGCTCCCAGGTCTGTCCCCGTGGCCACC",
        "ACGCTGCCTGCCGCGTACGCCACCCCGCAGCCAGGGACCCCGGTGTCCCC",
        "CGTGCAGTACGCTCACCTGCCGCACACCTTCCAGTTCATTGGGTCCTCCC",
        "AATACAGTGGAACCTATGCCAGCTTCATCCCATCACAGCTGATCCCCCCA",
        "ACCGCCAACCCCGTCACCAGTGCAGTGGCCTCGGCCGCAGGGGCCACCAC",
        "TCCATCCCAGCGCTCCCAGCTGGAGGCCTATTCCACTCTGCTGGCCAACA",
        "TGGGCAGTCTGAGCCAGACGCCGGGACACAAGGCTGAGCAGCAGCAGCAG",
    ]
    seq = "".join(seq)

Before we do anything, we need to consider first what our null hypothesis will "look" like and to use that perspective in deciding how we will approach this problem algorithmically. If nucleotides occur randomly within a DNA sequence, we expect that the dinucleotides will consist of randomly drawn nucleotides. Stated another way, we construct a dinucleotide by randomly drawing the first nucleotide from the pool of nucleotides and then drawing the second nucleotide from the same pool of nucleotides. In terms of a probability calculation, we expect the probability of dinucleotide :math:`i, j` to be specified as

.. math::

    p(i,j) = p(i)\times p(j)

where :math:`p(i,j)` is the probability of dinucleotide :math:`i,j`, and :math:`p(i)`, :math:`p(i)` the probabilities of nucleotides :math:`i` and :math:`j` respectively.

This is actually the calculation made when we perform a chi-square test for independence, so we will do that here. Let's use this simple DNA sequence -- ``"AACCCCGT"`` -- to illustrate the steps we need to take in order to be able to compute a chi-square statistic.

#. **Split the sequence into dinucleotides**: From our sample sequence, we need to produce the series of dinucleotides ``["AA", "CC", "CC", "GT"]``.

    .. jupyter-execute::
        :linenos:

        def seq_to_dinucs(seq):
            seq = "".join(seq)
            dinucs = [seq[i: i + 2] for i in range(0, len(seq) - 1, 2)]
            return dinucs
    
        dinucs = seq_to_dinucs("AACCCCGT")

#. **Define a nucleotide order**: We need this in order to be able to convert the dinucleotide string into array coordinates. We define nucleotides to be in alphabetical order. This means that the dinucleotide ``"AA"`` corresponds to indices ``(0, 0)`` while ``GT`` corresponds to indices ``(2, 3)``.

    .. jupyter-execute::
        :linenos:
    
        nucleotide_order = "ACGT"

#. **Convert dinucleotides into pairs of indices**: I'll do this by writing a function that converts a single dinucleotide into coordinates. Applying this to the sample sequence we get

    .. jupyter-execute::
        :linenos:
    
        def dinuc_to_indices(dinuc):
            return tuple(nucleotide_order.index(nuc) for nuc in dinuc)
        
        coords = [dinuc_to_indices(dinuc) for dinuc in dinucs]
        coords

#. **Use dinucleotide indices to increment counts in a matrix**: We will use a numpy array for the counts. Think of the row and column labels for this as array corresponding to the nucleotides present at the first and second position of a dinucleotide. For our example, we get the following

    .. jupyter-execute::

      from numpy import zeros
  
      def make_counts_matrix(coords):
          counts = zeros((4,4), dtype=int)
          for i, j in coords:
              counts[i, j] += 1
          return counts
      
      observed = make_counts_matrix(coords)
      observed

#. **Use those counts to compute the expected values**: This can be achieved quite simply here by first generating row and column sums, converting those to frequencies plus a couple of other steps (detail is below).

    .. jupyter-execute::
        :linenos:
        
        from numpy import outer

        def get_expected(counts):
            total = counts.sum()
            row_sums = counts.sum(axis=1)
            col_sums = counts.sum(axis=0)

            row_probs = row_sums / total
            col_probs = col_sums / total
            expecteds = outer(row_probs, col_probs) * total

            return expecteds
        
        expected = get_expected(observed)
        expected

#. **Generate the chi-square statistic**: This is defined as follows

    .. math::

        \chi^2=\sum_i\frac{(O_i-E_i)^2}{E_i}

    Where :math:`O_i` and :math:`E_i` correspond to the observed and expected counts for dinucleotide :math:`i` and the summation is over all dinucleotides.

    We express this as a Python function and apply it to our simple example. (The numpy array operations greatly simplify the calculation.)
    
    .. jupyter-execute::
        :linenos:
    
        def calc_chisq(observed, expected):
            chisq = (observed - expected)**2 / expected
            return chisq.sum()
    
        calc_chisq(observed, expected)

.. note:: The ``nan`` that was output from the ``calc_chisq()`` was generated because we were doing a division with 0 in the denominator. So time to switch to using the full sequence now.

Let's provide a simplified interface to all these function calls such that if we provide our sequence, all the above steps are called and we get back our chi-square statistic.

.. jupyter-execute::
    :linenos:

    def chiqsq_independent_nucs(seq):
        dinucs = seq_to_dinucs(seq)
        coords = [dinuc_to_indices(dinuc) for dinuc in dinucs]
        observed = make_counts_matrix(coords)
        expected = get_expected(observed)
        return calc_chisq(observed, expected)

    chiqsq_independent_nucs(seq)

So that's nice, we are now able to compute the statistic of interest given our sequence. How do we generate the null? We can generate synthetic data sets consistent with the null by randomly sampling from our actual data. This requires we have a means for making a random choice of a nucleotide to sample from our observed data. Algorithms for generating pseudo-random numbers are important for scientific computing and, as you might expect, there are numerous choices. (The Python standard library comes with a builtin capability for generating such numbers using a well regarded algorithm.) In our case, we can just use a ``shuffle`` function. Note that ``shuffle`` works "in place", meaning it modifies the data you provide, so we need to convert our sequence into a list.

.. jupyter-execute::
    :linenos:

    from numpy.random import shuffle
    
    tmp = list("AACCCCGT")
    shuffle(tmp)
    tmp

Will our functions still work if we give them a list?

.. jupyter-execute::
    :linenos:

    chiqsq_independent_nucs(list(seq))

Yup!

To recap, we have a function that (given a sequence) returns the chi-square statistic for the independence of the nucleotides at the first and second positions of dinucleotides. We want to generate the null distribution for this statistic so that we can assess how unusual the statistic from the observed data is. We do that by defining how many synthetic replicates we want to generate (we will call this ``num_reps``). Each of these synthetic sequences is generated in accordance with the null (the order of nucleotides is random) and a chi-square statistic computed. We can therefore use the number of these chi-square values from the generated null distribution that are ≥ than the chi-square from the observed sequence (we denote this quantity :math:`k`) to estimate the :math:`p`-value for our observed value as :math:`\frac{k}{num\_reps}`.

So here's the final function.

.. jupyter-execute::
    :linenos:

    def calc_chisq_pval(seq, num_reps):
        obs_stat = chiqsq_independent_nucs(seq)
        seq = list(seq)
        k = 0
        for i in range(num_reps):
            shuffle(seq)
            chisq = chiqsq_independent_nucs(seq)
            if chisq >= obs_stat:
                k += 1
        return k / num_reps

    calc_chisq_pval(seq, 2000)

If we compare this result to one obtained by explicitly using the chi-square distribution we can see they are very close.

.. jupyter-execute::
    :hide-code:

    from cogent3.maths.stats.number import CategoryCounter
    from cogent3.maths.stats.contingency import CategoryCounts

    c = CategoryCounter([(n1, n2) for n1, n2 in seq_to_dinucs(seq)])
    c = CategoryCounts(c)
    c.chisq_test().statistics

Parametric based simulation
---------------------------

This is another simulation based approach to inference. It differs in an important way from the above -- you have a "generating" model. What that means is you have a full probabilistic expression that you can then use to produce synthetic observations.

For the PSSM case, for example, the background model (equiprobable states) is a generating model.

------

.. rubric:: Citations

.. bibliography:: /references.bib
    :filter: docname in docnames
    :style: alpha
